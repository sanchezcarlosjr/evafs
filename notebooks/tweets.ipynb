{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "%run helpers.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a3c313f-d952-460f-891e-2d33081e0bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46fbec6c07f74081a9c09360add3816f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 64.00 MiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m SentenceTransformer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAlibaba-NLP/gte-Qwen1.5-7B-instruct\u001b[39m\u001b[38;5;124m\"\u001b[39m, trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Reduce the maximum sequence length if texts are not that long\u001b[39;00m\n\u001b[1;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39mmax_seq_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m512\u001b[39m  \u001b[38;5;66;03m# Adjust based on your typical input length\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/evafs/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py:221\u001b[0m, in \u001b[0;36mSentenceTransformer.__init__\u001b[0;34m(self, model_name_or_path, modules, device, prompts, default_prompt_name, cache_folder, trust_remote_code, revision, token, use_auth_token, truncate_dim)\u001b[0m\n\u001b[1;32m    218\u001b[0m     device \u001b[38;5;241m=\u001b[39m get_device_name()\n\u001b[1;32m    219\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse pytorch device_name: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(device))\n\u001b[0;32m--> 221\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_hpu_graph_enabled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_prompt_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_prompt_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprompts:\n",
      "File \u001b[0;32m~/.conda/envs/evafs/lib/python3.11/site-packages/torch/nn/modules/module.py:1173\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1170\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1171\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply(convert)\n",
      "File \u001b[0;32m~/.conda/envs/evafs/lib/python3.11/site-packages/torch/nn/modules/module.py:779\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    778\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 779\u001b[0m         module\u001b[38;5;241m.\u001b[39m_apply(fn)\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/evafs/lib/python3.11/site-packages/torch/nn/modules/module.py:779\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    778\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 779\u001b[0m         module\u001b[38;5;241m.\u001b[39m_apply(fn)\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 779 (3 times)]\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/evafs/lib/python3.11/site-packages/torch/nn/modules/module.py:779\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    778\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 779\u001b[0m         module\u001b[38;5;241m.\u001b[39m_apply(fn)\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/evafs/lib/python3.11/site-packages/torch/nn/modules/module.py:804\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 804\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m fn(param)\n\u001b[1;32m    805\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    807\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/evafs/lib/python3.11/site-packages/torch/nn/modules/module.py:1159\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1153\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1154\u001b[0m             device,\n\u001b[1;32m   1155\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1156\u001b[0m             non_blocking,\n\u001b[1;32m   1157\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1158\u001b[0m         )\n\u001b[0;32m-> 1159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1160\u001b[0m         device,\n\u001b[1;32m   1161\u001b[0m         dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1162\u001b[0m         non_blocking,\n\u001b[1;32m   1163\u001b[0m     )\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 64.00 MiB. GPU "
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"Alibaba-NLP/gte-Qwen1.5-7B-instruct\", trust_remote_code=True)\n",
    "# In case you want to reduce the maximum length:\n",
    "model.max_seq_length = 8192\n",
    "\n",
    "queries = [\n",
    "    \"how much protein should a female eat\",\n",
    "    \"summit define\",\n",
    "]\n",
    "documents = [\n",
    "    \"As a general guideline, the CDC's average requirement of protein for women ages 19 to 70 is 46 grams per day. But, as you can see from this chart, you'll need to increase that if you're expecting or training for a marathon. Check out the chart below to see how much protein you should be eating each day.\",\n",
    "    \"Definition of summit for English Language Learners. : 1  the highest point of a mountain : the top of a mountain. : 2  the highest level. : 3  a meeting or series of meetings between the leaders of two or more governments.\",\n",
    "]\n",
    "\n",
    "query_embeddings = model.encode(queries, prompt_name=\"query\")\n",
    "document_embeddings = model.encode(documents)\n",
    "\n",
    "scores = (query_embeddings @ document_embeddings.T) * 100\n",
    "print(scores.tolist())\n",
    "# [[70.00668334960938, 8.184843063354492], [14.62419319152832, 77.71407318115234]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8124fef7-bf65-4461-bb1d-7430f9767773",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name='meta-llama/Meta-Llama-3-8B-Instruct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e95563d-a1e7-424c-b469-f0f0f71759b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings.embed_query(\"18\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a8573e3-2aff-4f6d-8eae-2f46997fac8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.22234759326547837}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.evaluation import load_evaluator\n",
    "\n",
    "hf_evaluator = load_evaluator(\"pairwise_embedding_distance\", embeddings=embeddings)\n",
    "hf_evaluator.evaluate_string_pairs(\n",
    "    prediction=\"dieciocho\", prediction_b=\"18\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8dc66bd-f9f3-48be-919a-922b29590d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_postgres import PGVector\n",
    "from langchain_postgres.vectorstores import PGVector\n",
    "\n",
    "# See docker command above to launch a postgres instance with pgvector enabled.\n",
    "connection = \"postgresql+psycopg://postgres:postgres@127.0.0.1:54322/postgres\"  # Uses psycopg3!\n",
    "collection_name = \"dataset\"\n",
    "\n",
    "vectorstore = PGVector(\n",
    "    embeddings=embeddings,\n",
    "    collection_name=collection_name,\n",
    "    connection=connection,\n",
    "    use_jsonb=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2459a2f-d87d-44cd-aab0-a70b1a33ea2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id_EXIST': '100001',\n",
       " 'lang': 'es',\n",
       " 'tweet': '@TheChiflis Ignora al otro, es un capullo.El problema con este youtuber denuncia el acoso... cuando no afecta a la gente de izquierdas. Por ejemplo, en su video sobre el gamergate presenta como \"normal\" el acoso que reciben Fisher, Anita o Zöey cuando hubo hasta amenazas de bomba.',\n",
       " 'number_annotators': 6,\n",
       " 'annotators': ['Annotator_1',\n",
       "  'Annotator_2',\n",
       "  'Annotator_3',\n",
       "  'Annotator_4',\n",
       "  'Annotator_5',\n",
       "  'Annotator_6'],\n",
       " 'gender_annotators': ['F', 'F', 'F', 'M', 'M', 'M'],\n",
       " 'age_annotators': ['18-22', '23-45', '46+', '46+', '23-45', '18-22'],\n",
       " 'ethnicities_annotators': ['White or Caucasian',\n",
       "  'Hispano or Latino',\n",
       "  'White or Caucasian',\n",
       "  'White or Caucasian',\n",
       "  'White or Caucasian',\n",
       "  'Hispano or Latino'],\n",
       " 'study_levels_annotators': ['Bachelor’s degree',\n",
       "  'Bachelor’s degree',\n",
       "  'High school degree or equivalent',\n",
       "  'Master’s degree',\n",
       "  'Master’s degree',\n",
       "  'High school degree or equivalent'],\n",
       " 'countries_annotators': ['Italy',\n",
       "  'Mexico',\n",
       "  'United States',\n",
       "  'Spain',\n",
       "  'Spain',\n",
       "  'Chile'],\n",
       " 'labels_task1': ['YES', 'YES', 'NO', 'YES', 'YES', 'YES'],\n",
       " 'labels_task2': ['REPORTED',\n",
       "  'JUDGEMENTAL',\n",
       "  '-',\n",
       "  'REPORTED',\n",
       "  'JUDGEMENTAL',\n",
       "  'REPORTED'],\n",
       " 'labels_task3': [['OBJECTIFICATION'],\n",
       "  ['OBJECTIFICATION', 'SEXUAL-VIOLENCE'],\n",
       "  ['-'],\n",
       "  ['STEREOTYPING-DOMINANCE'],\n",
       "  ['SEXUAL-VIOLENCE'],\n",
       "  ['IDEOLOGICAL-INEQUALITY', 'MISOGYNY-NON-SEXUAL-VIOLENCE']],\n",
       " 'split': 'TRAIN_ES'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr = tweet_training()\n",
    "tr['100001']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59d1351c-a23f-481a-8320-d99f2ef366a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import uuid\n",
    "\n",
    "URL_RE = re.compile(r\"https?:\\/\\/[\\w\\.\\/\\?\\=\\d%_:/-]+\")\n",
    "HANDLE_RE = re.compile(r\"@\\w+\")\n",
    "\n",
    "def vote(item):\n",
    "    return item[\"labels_task1\"].count(\"YES\")/len(item[\"labels_task1\"])\n",
    "\n",
    "def to_document(item):\n",
    "    return Document(\n",
    "        page_content=URL_RE.sub(\"HTTPURL\", HANDLE_RE.sub(\"@USER\", item['tweet'])),\n",
    "        metadata={\"id\": str(uuid.uuid4()), \"task1\": vote(item), 'document_id': item['id_EXIST'], 'lang': item['lang']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf3098a-79c4-4553-aefa-857214842b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = list(map(to_document, tr.values()))\n",
    "vectorstore.add_documents(docs, ids=[doc.metadata[\"id\"] for doc in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82c20526-363e-43ef-9ca2-8e272295b471",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(query):\n",
    "    document = vectorstore.similarity_search(query['tweet'], k=1)[0]\n",
    "    return {\n",
    "        'test_case': \"EXIST2024\",\n",
    "        'id': query['id_EXIST'],\n",
    "        'value': document.metadata['task1']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8ee4196-221f-421b-aad8-775c7ebecd35",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tweet_dev' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dev \u001b[38;5;241m=\u001b[39m tweet_dev()\n\u001b[1;32m      2\u001b[0m results \u001b[38;5;241m=\u001b[39m apply_predict_to(dev, \u001b[38;5;28;01mlambda\u001b[39;00m item: predict(item))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tweet_dev' is not defined"
     ]
    }
   ],
   "source": [
    "dev = tweet_dev()\n",
    "results = apply_predict_to(dev, lambda item: predict(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cf5e3aff-bc19-4421-a800-2e87b227dc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"EXIST2024_dev_task1_majority_class_hard.json\", \"w\")  \n",
    "json.dump(results, file, indent = 6)  \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0214cea-d5d5-4052-baa8-019d56d0fd4b",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4eefbf6d-0a0f-4fc3-bfb7-2901cec52a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-03 15:55:16,793 - pyevall.evaluation - INFO -             evaluate() - Evaluating the following metrics ['ICM', 'ICMNorm', 'FMeasure', 'Accuracy', 'Precision', 'Recall']\n",
      "2024-05-03 15:55:16,854 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM evaluation method\n",
      "2024-05-03 15:55:17,004 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM Normalized evaluation method\n",
      "2024-05-03 15:55:17,005 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM evaluation method\n",
      "2024-05-03 15:55:17,153 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM evaluation method\n",
      "2024-05-03 15:55:17,296 - pyevall.metrics.metrics - INFO -             evaluate() - Executing fmeasure evaluation method\n",
      "2024-05-03 15:55:17,439 - pyevall.metrics.metrics - INFO -             evaluate() - Executing accuracy evaluation method\n",
      "2024-05-03 15:55:17,439 - pyevall.metrics.metrics - INFO -             evaluate() - Executing precision evaluation method\n",
      "2024-05-03 15:55:17,440 - pyevall.metrics.metrics - INFO -             evaluate() - Executing recall evaluation method\n",
      "{\n",
      "  \"metrics\": {\n",
      "    \"ICM\": {\n",
      "      \"name\": \"Information Contrast model\",\n",
      "      \"acronym\": \"ICM\",\n",
      "      \"description\": \"Coming soon!\",\n",
      "      \"status\": \"OK\",\n",
      "      \"results\": {\n",
      "        \"test_cases\": [{\n",
      "          \"name\": \"EXIST2024\",\n",
      "          \"average\": -0.48069213773915614\n",
      "        }],\n",
      "        \"average_per_test_case\": -0.48069213773915614\n",
      "      }\n",
      "    },\n",
      "    \"ICMNorm\": {\n",
      "      \"name\": \"Normalized Information Contrast Model\",\n",
      "      \"acronym\": \"ICM-Norm\",\n",
      "      \"description\": \"Coming soon!\",\n",
      "      \"status\": \"OK\",\n",
      "      \"results\": {\n",
      "        \"test_cases\": [{\n",
      "          \"name\": \"EXIST2024\",\n",
      "          \"average\": 0.25953938906154145\n",
      "        }],\n",
      "        \"average_per_test_case\": 0.25953938906154145\n",
      "      }\n",
      "    },\n",
      "    \"FMeasure\": {\n",
      "      \"name\": \"F-Measure\",\n",
      "      \"acronym\": \"F1\",\n",
      "      \"description\": \"Coming soon!\",\n",
      "      \"status\": \"OK\",\n",
      "      \"results\": {\n",
      "        \"test_cases\": [{\n",
      "          \"name\": \"EXIST2024\",\n",
      "          \"classes\": {\n",
      "            \"YES\": 0,\n",
      "            \"NO\": 0.6315095583388266\n",
      "          },\n",
      "          \"average\": 0.3157547791694133\n",
      "        }],\n",
      "        \"average_per_test_case\": 0.3157547791694133\n",
      "      }\n",
      "    },\n",
      "    \"Accuracy\": {\n",
      "      \"name\": \"Accuracy\",\n",
      "      \"acronym\": \"Acc\",\n",
      "      \"description\": \"Coming soon!\",\n",
      "      \"status\": \"OK\",\n",
      "      \"results\": {\n",
      "        \"test_cases\": [{\n",
      "          \"name\": \"EXIST2024\",\n",
      "          \"average\": 0.512847965738758\n",
      "        }],\n",
      "        \"average_per_test_case\": 0.512847965738758\n",
      "      }\n",
      "    },\n",
      "    \"Precision\": {\n",
      "      \"name\": \"Precision\",\n",
      "      \"acronym\": \"Pr\",\n",
      "      \"description\": \"Coming soon!\",\n",
      "      \"status\": \"OK\",\n",
      "      \"results\": {\n",
      "        \"test_cases\": [{\n",
      "          \"name\": \"EXIST2024\",\n",
      "          \"classes\": {\n",
      "            \"YES\": null,\n",
      "            \"NO\": 0.4614643545279383\n",
      "          },\n",
      "          \"average\": 0.4614643545279383\n",
      "        }],\n",
      "        \"average_per_test_case\": 0.4614643545279383\n",
      "      }\n",
      "    },\n",
      "    \"Recall\": {\n",
      "      \"name\": \"Recall\",\n",
      "      \"acronym\": \"Re\",\n",
      "      \"description\": \"Coming soon!\",\n",
      "      \"status\": \"OK\",\n",
      "      \"results\": {\n",
      "        \"test_cases\": [{\n",
      "          \"name\": \"EXIST2024\",\n",
      "          \"classes\": {\n",
      "            \"YES\": 0.0,\n",
      "            \"NO\": 1.0\n",
      "          },\n",
      "          \"average\": 0.5\n",
      "        }],\n",
      "        \"average_per_test_case\": 0.5\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"files\": {\n",
      "    \"EXIST2024_dev_task1_majority_class_hard.json\": {\n",
      "      \"name\": \"EXIST2024_dev_task1_majority_class_hard.json\",\n",
      "      \"status\": \"OK\",\n",
      "      \"gold\": false,\n",
      "      \"description\": \"The file is correctly parser without errors or warnings.\\\\nFile name: EXIST2024_dev_task1_majority_class_hard.json.\",\n",
      "      \"errors\": {}\n",
      "    },\n",
      "    \"EXIST2024_dev_task1_gold_hard.json\": {\n",
      "      \"name\": \"EXIST2024_dev_task1_gold_hard.json\",\n",
      "      \"status\": \"OK\",\n",
      "      \"gold\": true,\n",
      "      \"description\": \"The file is correctly parser without errors or warnings.\\\\nFile name: EXIST2024_dev_task1_gold_hard.json.\",\n",
      "      \"errors\": {}\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from pyevall.evaluation import PyEvALLEvaluation\n",
    "from pyevall.utils.utils import PyEvALLUtils\n",
    "\n",
    "baseline = tweet_baseline(\"EXIST2024_dev_task1_majority_class_hard.json\")\n",
    "gold = tweet_golds(\"EXIST2024_dev_task1_gold_hard.json\")\n",
    "test = PyEvALLEvaluation()\n",
    "params= dict()\n",
    "params[PyEvALLUtils.PARAM_REPORT]= PyEvALLUtils.PARAM_OPTION_REPORT_EMBEDDED\n",
    "metrics=[\"ICM\", \"ICMNorm\" ,\"FMeasure\", \"Accuracy\", \"Precision\", \"Recall\"]\n",
    "report= test.evaluate(baseline, gold, metrics, **params)\n",
    "report.print_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "45a62be6-4b30-41a5-a369-e266a087060e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-03 15:57:36,135 - pyevall.evaluation - INFO -             evaluate() - Evaluating the following metrics ['ICM', 'ICMNorm', 'FMeasure', 'Accuracy', 'Precision', 'Recall']\n",
      "2024-05-03 15:57:36,187 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM evaluation method\n",
      "2024-05-03 15:57:36,341 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM Normalized evaluation method\n",
      "2024-05-03 15:57:36,341 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM evaluation method\n",
      "2024-05-03 15:57:36,497 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM evaluation method\n",
      "2024-05-03 15:57:36,645 - pyevall.metrics.metrics - INFO -             evaluate() - Executing fmeasure evaluation method\n",
      "2024-05-03 15:57:36,790 - pyevall.metrics.metrics - INFO -             evaluate() - Executing accuracy evaluation method\n",
      "2024-05-03 15:57:36,791 - pyevall.metrics.metrics - INFO -             evaluate() - Executing precision evaluation method\n",
      "2024-05-03 15:57:36,791 - pyevall.metrics.metrics - INFO -             evaluate() - Executing recall evaluation method\n",
      "{\n",
      "  \"metrics\": {\n",
      "    \"ICM\": {\n",
      "      \"name\": \"Information Contrast model\",\n",
      "      \"acronym\": \"ICM\",\n",
      "      \"description\": \"Coming soon!\",\n",
      "      \"status\": \"OK\",\n",
      "      \"results\": {\n",
      "        \"test_cases\": [{\n",
      "          \"name\": \"EXIST2024\",\n",
      "          \"average\": 0.04347999595686117\n",
      "        }],\n",
      "        \"average_per_test_case\": 0.04347999595686117\n",
      "      }\n",
      "    },\n",
      "    \"ICMNorm\": {\n",
      "      \"name\": \"Normalized Information Contrast Model\",\n",
      "      \"acronym\": \"ICM-Norm\",\n",
      "      \"description\": \"Coming soon!\",\n",
      "      \"status\": \"OK\",\n",
      "      \"results\": {\n",
      "        \"test_cases\": [{\n",
      "          \"name\": \"EXIST2024\",\n",
      "          \"average\": 0.521750358640278\n",
      "        }],\n",
      "        \"average_per_test_case\": 0.521750358640278\n",
      "      }\n",
      "    },\n",
      "    \"FMeasure\": {\n",
      "      \"name\": \"F-Measure\",\n",
      "      \"acronym\": \"F1\",\n",
      "      \"description\": \"Coming soon!\",\n",
      "      \"status\": \"OK\",\n",
      "      \"results\": {\n",
      "        \"test_cases\": [{\n",
      "          \"name\": \"EXIST2024\",\n",
      "          \"classes\": {\n",
      "            \"YES\": 0.6197183098591549,\n",
      "            \"NO\": 0.669208770257388\n",
      "          },\n",
      "          \"average\": 0.6444635400582714\n",
      "        }],\n",
      "        \"average_per_test_case\": 0.6444635400582714\n",
      "      }\n",
      "    },\n",
      "    \"Accuracy\": {\n",
      "      \"name\": \"Accuracy\",\n",
      "      \"acronym\": \"Acc\",\n",
      "      \"description\": \"Coming soon!\",\n",
      "      \"status\": \"OK\",\n",
      "      \"results\": {\n",
      "        \"test_cases\": [{\n",
      "          \"name\": \"EXIST2024\",\n",
      "          \"average\": 0.6820128479657388\n",
      "        }],\n",
      "        \"average_per_test_case\": 0.6820128479657388\n",
      "      }\n",
      "    },\n",
      "    \"Precision\": {\n",
      "      \"name\": \"Precision\",\n",
      "      \"acronym\": \"Pr\",\n",
      "      \"description\": \"Coming soon!\",\n",
      "      \"status\": \"OK\",\n",
      "      \"results\": {\n",
      "        \"test_cases\": [{\n",
      "          \"name\": \"EXIST2024\",\n",
      "          \"classes\": {\n",
      "            \"YES\": 0.6111111111111112,\n",
      "            \"NO\": 0.6157894736842106\n",
      "          },\n",
      "          \"average\": 0.6134502923976608\n",
      "        }],\n",
      "        \"average_per_test_case\": 0.6134502923976608\n",
      "      }\n",
      "    },\n",
      "    \"Recall\": {\n",
      "      \"name\": \"Recall\",\n",
      "      \"acronym\": \"Re\",\n",
      "      \"description\": \"Coming soon!\",\n",
      "      \"status\": \"OK\",\n",
      "      \"results\": {\n",
      "        \"test_cases\": [{\n",
      "          \"name\": \"EXIST2024\",\n",
      "          \"classes\": {\n",
      "            \"YES\": 0.6285714285714286,\n",
      "            \"NO\": 0.732776617954071\n",
      "          },\n",
      "          \"average\": 0.6806740232627497\n",
      "        }],\n",
      "        \"average_per_test_case\": 0.6806740232627497\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"files\": {\n",
      "    \"EXIST2024_dev_task1_majority_class_hard.json\": {\n",
      "      \"name\": \"EXIST2024_dev_task1_majority_class_hard.json\",\n",
      "      \"status\": \"OK\",\n",
      "      \"gold\": false,\n",
      "      \"description\": \"The file is correctly parser without errors or warnings.\\\\nFile name: EXIST2024_dev_task1_majority_class_hard.json.\",\n",
      "      \"errors\": {}\n",
      "    },\n",
      "    \"EXIST2024_dev_task1_gold_hard.json\": {\n",
      "      \"name\": \"EXIST2024_dev_task1_gold_hard.json\",\n",
      "      \"status\": \"OK\",\n",
      "      \"gold\": true,\n",
      "      \"description\": \"The file is correctly parser without errors or warnings.\\\\nFile name: EXIST2024_dev_task1_gold_hard.json.\",\n",
      "      \"errors\": {}\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from pyevall.evaluation import PyEvALLEvaluation\n",
    "from pyevall.utils.utils import PyEvALLUtils\n",
    "\n",
    "predictions = 'EXIST2024_dev_task1_majority_class_hard.json'\n",
    "gold = tweet_golds(\"EXIST2024_dev_task1_gold_hard.json\")\n",
    "test = PyEvALLEvaluation()\n",
    "params= dict()\n",
    "params[PyEvALLUtils.PARAM_REPORT]= PyEvALLUtils.PARAM_OPTION_REPORT_EMBEDDED\n",
    "metrics=[\"ICM\", \"ICMNorm\" ,\"FMeasure\", \"Accuracy\", \"Precision\", \"Recall\"]\n",
    "report= test.evaluate(predictions, gold, metrics, **params)\n",
    "report.print_report()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evafs",
   "language": "python",
   "name": "evafs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
